{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3750df3",
      "metadata": {
        "id": "d3750df3"
      },
      "source": [
        "# Exercise: Object Counting Using YOLO with a Line in the Middle of the Frame\n",
        "In this exercise, you will implement an object counting system using YOLOv8. You will process a video and count the number of objects crossing a line drawn in the middle of the frame. Follow the steps below to complete the exercise.\n",
        "\n",
        "## Objective:\n",
        "The goal is to load a video, detect objects, count them as they cross a line, and save the processed video with the results.\n",
        "\n",
        "## Steps to Complete:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0c358a6",
      "metadata": {
        "id": "c0c358a6"
      },
      "source": [
        "### Step 1: Install the Required Libraries\n",
        "- Install the `ultralytics` library using pip to work with YOLOv8.\n",
        "- Also ensure you have OpenCV installed for video processing.\n",
        "\n",
        "_Hint_: You can install a library using the `!pip install` command in a code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b485770c",
      "metadata": {
        "id": "b485770c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3418c064",
      "metadata": {
        "id": "3418c064"
      },
      "source": [
        "### Step 2: Import the Libraries\n",
        "- Import the necessary libraries, including `cv2` from OpenCV and `YOLO` from `ultralytics`.\n",
        "- You will also need to import any other required libraries for object counting and video handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b0204dd1",
      "metadata": {
        "id": "b0204dd1",
        "outputId": "219a3cc2-407c-433e-9445-e73b2bf7f111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m871.1/871.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO, solutions # solutions to count the objects"
      ],
      "metadata": {
        "id": "yOk-D7EZpPtu"
      },
      "id": "yOk-D7EZpPtu",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0d18b3ee",
      "metadata": {
        "id": "0d18b3ee"
      },
      "source": [
        "### Step 3: Load the YOLO Model\n",
        "- Load the pre-trained YOLOv8 model (e.g., `yolov8n.pt`) to perform object detection and tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d6d8b7ca",
      "metadata": {
        "id": "d6d8b7ca",
        "outputId": "d7846fd1-6948-4b17-cd08-96b4e42c3285",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.25M/6.25M [00:00<00:00, 93.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a013f91a",
      "metadata": {
        "id": "a013f91a"
      },
      "source": [
        "### Step 4: Capture and Process the Video\n",
        "- Use OpenCV to capture the video from a specified file path.\n",
        "- Ensure the video file opens successfully and retrieve the video properties (such as width, height, and frames per second)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4969f806",
      "metadata": {
        "id": "4969f806"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('/content/sample_data/vehicle-counting.mp4')\n",
        "assert cap.isOpened(), 'Error reading video file'\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76c53c44",
      "metadata": {
        "id": "76c53c44"
      },
      "source": [
        "### Step 5: Define the Line in the Middle of the Frame\n",
        "- Calculate the vertical middle of the frame using the height of the video.\n",
        "- Define two points to represent a horizontal line in the middle of the frame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f917b88a",
      "metadata": {
        "id": "f917b88a"
      },
      "outputs": [],
      "source": [
        "mid_y = h // 2 # mid of the object\n",
        "line_points = [(20, mid_y), (w - 20, mid_y)] # direction of the line"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e45736",
      "metadata": {
        "id": "23e45736"
      },
      "source": [
        "### Step 6: Set Up the Video Writer\n",
        "- Create a video writer object to save the output video in MP4 format.\n",
        "- Choose the appropriate codec and ensure the output video properties match the input video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "79307270",
      "metadata": {
        "id": "79307270"
      },
      "outputs": [],
      "source": [
        "video_writer = cv2.VideoWriter('object_counting_output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b7f4ffd",
      "metadata": {
        "id": "6b7f4ffd"
      },
      "source": [
        "### Step 7: Initialize the Object Counter\n",
        "- Use the `solutions.ObjectCounter` class to handle the object counting logic.\n",
        "- Pass in the necessary parameters, including the line points, object names, and any visual settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "79b41d23",
      "metadata": {
        "id": "79b41d23",
        "outputId": "80776955-da46-48f8-fd06-613eb6f782a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n",
            "Line Counter Initiated.\n"
          ]
        }
      ],
      "source": [
        "counter = solutions.ObjectCounter(\n",
        "    view_img=True,\n",
        "    reg_pts=line_points,\n",
        "    names=model.names, #name of classes\n",
        "    draw_tracks=True,\n",
        "    line_thickness=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edf12972",
      "metadata": {
        "id": "edf12972"
      },
      "source": [
        "### Step 8: Process the Video Frames\n",
        "- Loop through each frame of the video using OpenCV.\n",
        "- Apply YOLOv8 to detect and track objects in each frame.\n",
        "- Use the object counter to count the number of objects crossing the line.\n",
        "- Write each processed frame to the output video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a0228c1c",
      "metadata": {
        "id": "a0228c1c"
      },
      "outputs": [],
      "source": [
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print('Video frame is empty or video processing has been successfully completed.')\n",
        "        break\n",
        "\n",
        "    # Perform object tracking\n",
        "    tracks = model.track(im0, persist=True, show=False) # model is track\n",
        "\n",
        "    # Count objects and draw the middle line\n",
        "    im0 = counter.start_counting(im0, tracks)\n",
        "    video_writer.write(im0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52822ce8",
      "metadata": {
        "id": "52822ce8"
      },
      "source": [
        "### Step 9: Release Resources\n",
        "- Once the video processing is complete, release the video capture and writer objects.\n",
        "- Close any OpenCV windows that were opened during the process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7567e053",
      "metadata": {
        "id": "7567e053"
      },
      "outputs": [],
      "source": [
        "cap.release()\n",
        "video_writer.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c85b11f5",
      "metadata": {
        "id": "c85b11f5"
      },
      "source": [
        "### Conclusion\n",
        "By completing this exercise, you will have implemented an object counting system using YOLOv8 and OpenCV. The final output will be a video with objects counted as they cross a line in the middle of the frame."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}