{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45fbb33b",
      "metadata": {
        "id": "45fbb33b"
      },
      "source": [
        "# LangChain Tutorial Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a0df42",
      "metadata": {
        "id": "34a0df42"
      },
      "source": [
        "\n",
        "In this notebook, you will practice using LangChain to interact with large language models (LLMs),\n",
        "build chains, agents, and utilize memory. Fill in the code blocks with your implementations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "169dd23c",
      "metadata": {
        "id": "169dd23c"
      },
      "source": [
        "## Exercise 1: Basic LLM Query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf03f4a7",
      "metadata": {
        "id": "bf03f4a7"
      },
      "source": [
        "In this exercise, you will set up a basic interaction with the GROQ LLaMA model using LangChain.\n",
        "\n",
        "1. Initialize the LLM (Use GROQ and chose LLM).\n",
        "2. Create a prompt that asks the LLM to generate a story about a topic.\n",
        "3. Run the LLM chain to retrieve the response.\n",
        "\n",
        "**Steps**:\n",
        "- Import required modules from `langchain`.\n",
        "- Initialize the LLM with your GROQ API key.\n",
        "- Create a prompt template that takes a topic as input.\n",
        "- Create an LLM Chain and run it to get a response.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5686ae2f",
      "metadata": {
        "id": "5686ae2f",
        "outputId": "e642310e-fad1-445d-8a30-3dff282262eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-6.2.11-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.121-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting primp>=0.6.1 (from duckduckgo-search)\n",
            "  Downloading primp-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq) (4.12.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m917.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading duckduckgo_search-6.2.11-py3-none-any.whl (27 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.121-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, python-dotenv, primp, orjson, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, duckduckgo-search, pydantic-settings, httpx, dataclasses-json, langsmith, groq, langchain-core, langchain-text-splitters, langchain-groq, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed dataclasses-json-0.6.7 duckduckgo-search-6.2.11 groq-0.11.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-community-0.3.0 langchain-core-0.3.0 langchain-groq-0.2.0 langchain-text-splitters-0.3.0 langsmith-0.1.121 marshmallow-3.22.0 mypy-extensions-1.0.0 orjson-3.10.7 primp-0.6.2 pydantic-settings-2.5.2 python-dotenv-1.0.1 tenacity-8.5.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-groq duckduckgo-search geopy requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key = \"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\""
      ],
      "metadata": {
        "id": "2J413-sTKKh5"
      },
      "id": "2J413-sTKKh5",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.1-8b-instant\",\n",
        "    temperature=0.8,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key=groq_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "tQz7sbTvKPIA"
      },
      "id": "tQz7sbTvKPIA",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Define the prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Write a short story about {topic}.\"\n",
        ")"
      ],
      "metadata": {
        "id": "szHZmMcaKsk_"
      },
      "id": "szHZmMcaKsk_",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "# Create an LLM chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Run the chain with a specific topic\n",
        "response = chain.run(\"summer in spain \") #generate response\n",
        "print(response)"
      ],
      "metadata": {
        "id": "hhR_gU1zLaGA",
        "outputId": "9cb1db26-2955-41e6-ea0f-b34741f819be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hhR_gU1zLaGA",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-365067324191>:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n",
            "<ipython-input-5-365067324191>:7: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
            "  response = chain.run(\"summer in spain \") #generate response\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**The Sizzling Streets of Valencia**\n",
            "\n",
            "Summer had descended upon Valencia, Spain, like a fiery kiss from the Mediterranean sun. The air was warm and languid, carrying the sweet scent of orange blossoms and the faint tang of sea salt. It was a time when the rhythm of the city slowed, and people surrendered to the languor of the season.\n",
            "\n",
            "Ana, a young artist, sat at a small café on the bustling Plaza de la Reina, watching the world go by through a haze of iced coffee and sunlight. Her long, dark hair was tied back in a loose ponytail, and her eyes sparkled with a hint of mischief. She was waiting for her friend, Carlos, a local musician, to arrive with his guitar.\n",
            "\n",
            "As she sipped her coffee, Ana felt the vibrant energy of the city surround her. The sound of flamenco music drifted from a nearby tavern, where a group of dancers were performing with wild abandon. The air was filled with the tantalizing aroma of paella, sizzling on the grills of street vendors.\n",
            "\n",
            "Carlos arrived, his guitar case slung over his shoulder, and together they set out to explore the city. They strolled through the tranquil gardens of the Turia Gardens, where the sound of running water and chirping birds filled the air. They laughed and joked, their spirits lifted by the warmth and beauty of the day.\n",
            "\n",
            "As the sun began to set, they made their way to the beach, where a group of friends were waiting to join them. The sky was ablaze with color, a fiery sunset that seemed to set the very sea itself on fire. They danced and sang, their voices carrying on the wind, as the stars began to twinkle in the night sky.\n",
            "\n",
            "As the night wore on, they made their way to a secluded spot near the sea, where a group of musicians were playing a lively flamenco tune. Ana and Carlos joined in, their voices blending with the music, as the night air pulsed with the rhythm of the guitars.\n",
            "\n",
            "In that moment, Ana felt a deep connection to the city, to the people, and to the music. She knew that this was what summer in Spain was all about – the joy, the passion, and the beauty that seemed to seep from every stone and every soul.\n",
            "\n",
            "As the music faded, and the night grew still, Ana leaned against Carlos, feeling the warmth of his body and the beat of his heart. She knew that this was just the beginning of a summer that would be etched in her memory forever, a summer of laughter, love, and the sweet, golden light of Spain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff1b3fa",
      "metadata": {
        "id": "1ff1b3fa"
      },
      "source": [
        "## Exercise 2: Building a Conversational Agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()"
      ],
      "metadata": {
        "id": "uyqb84SvLUAe"
      },
      "id": "uyqb84SvLUAe",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# List of tools the agent can use\n",
        "tools = [search]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")"
      ],
      "metadata": {
        "id": "ddPOW3nPLwlS"
      },
      "id": "ddPOW3nPLwlS",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4a6a1f26",
      "metadata": {
        "id": "4a6a1f26"
      },
      "source": [
        "\n",
        "In this exercise, you will create a conversational agent that can interact with a user, make decisions,\n",
        "and use external tools like a search tool.\n",
        "\n",
        "1. Define a tool.\n",
        "2. Create an agent that can decide whether to use the tool or interact with the LLM.\n",
        "3. Run the agent with various inputs.\n",
        "\n",
        "**Steps**:\n",
        "- Define the search tool using a function.\n",
        "- Initialize an agent using the tool and the LLM.\n",
        "- Run the agent with sample inputs.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a6e3e8e2",
      "metadata": {
        "id": "a6e3e8e2",
        "outputId": "c55c71d8-17b2-448e-b714-69ed0666c7ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Microsoft is a technology company that has recently announced a new share buy back program of up to $60 billion, approved by its board. The company is also celebrating its 50th year, with CEO Satya Nadella reflecting on its success and the importance of innovation and artificial intelligence. Additionally, Microsoft is working on various projects such as the Secure Future Initiative (SFI) to advance cybersecurity protection and has launched new Copilot+ PCs with the Microsoft Pluton security processor.\n"
          ]
        }
      ],
      "source": [
        "response = agent.run(\"Find information about Microsoft.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"What is DuckDuckGo? \")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "2ZiiD7nJMXvY",
        "outputId": "b9c8e746-d5fa-4906-eec2-42e5b28d8931",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2ZiiD7nJMXvY",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DuckDuckGo is a search engine that prioritizes user privacy, doesn't collect personal information, and doesn't alter search results based on a user's search history.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cf94d2f",
      "metadata": {
        "id": "3cf94d2f"
      },
      "source": [
        "## Exercise 3: Using LLM as Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ff48d9",
      "metadata": {
        "id": "53ff48d9"
      },
      "source": [
        "\n",
        "In this exercise, you will use an LLM to summarize and retain information from conversations.\n",
        "\n",
        "1. Set up LLM-based memory.\n",
        "2. Create a conversation with the LLM and memory.\n",
        "3. Ask follow-up questions using memory to retrieve past context.\n",
        "\n",
        "**Steps**:\n",
        "- Initialize summarization-based memory.\n",
        "- Run a few queries and retrieve responses.\n",
        "- Ask follow-up questions that reference previous interactions.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "796557b9",
      "metadata": {
        "id": "796557b9",
        "outputId": "7f943af7-84e8-4353-a74a-ca0ebd8e2b75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-ef489702cdd2>:11: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
            "  chain = ConversationChain(llm=llm, memory=memory)\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain import ConversationChain\n",
        "\n",
        "# Initialize summarization-based memory\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Clear memory\n",
        "memory.clear()\n",
        "\n",
        "# Create a chain with LLM and buffer memory\n",
        "chain = ConversationChain(llm=llm, memory=memory)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a conversation\n",
        "res1 = chain.run(\"Answer with short answer, give me three girl names\")\n",
        "res2 = chain.run(\"Answer with short answer, give me another three boy names\")\n",
        "res3 = chain.run(\"From the previous conversations. What which names were boy names and girl names ?\")\n",
        "\n",
        "print(f'First Response: {res1}\\nSecond Response: {res2}\\nThird Response: {res3}')"
      ],
      "metadata": {
        "id": "CFXDipF6Nlxg",
        "outputId": "c7d1913c-95e3-40a7-d0e4-d8a2ba383ca1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CFXDipF6Nlxg",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Response: Emily, Olivia, Ava.\n",
            "Second Response: Liam, Noah, Ethan.\n",
            "Third Response: From the previous conversation, the boy names were:\n",
            "1. Liam\n",
            "2. Noah\n",
            "3. Ethan\n",
            "\n",
            "The girl names were:\n",
            "1. Emily\n",
            "2. Olivia\n",
            "3. Ava\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630fe2fb",
      "metadata": {
        "id": "630fe2fb"
      },
      "source": [
        "## Exercise 4: Combining Tools and Memory"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17dba76c",
      "metadata": {
        "id": "17dba76c"
      },
      "source": [
        "\n",
        "In this final exercise, you will build an intelligent agent that can use both tools (like an API) and memory.\n",
        "\n",
        "1. Define an external tool (like a weather API).\n",
        "2. Set up an agent that uses both the tool and LLM memory.\n",
        "3. Interact with the agent, combining memory and external data.\n",
        "\n",
        "**Steps**:\n",
        "- Define a weather API tool (mock or real API).\n",
        "- Initialize the agent with memory and the tool.\n",
        "- Run the agent with inputs, and check how it uses both memory and tools.\n",
        "\n",
        "Fill in the code below:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "geolocator = Nominatim(user_agent=\"LLMexercise\")"
      ],
      "metadata": {
        "id": "eePw6rCvOcM2"
      },
      "id": "eePw6rCvOcM2",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_name = 'Riyadh Saudi Arabia '\n",
        "location = geolocator.geocode(city_name)\n",
        "location"
      ],
      "metadata": {
        "id": "eXmeb1Q5OrrH",
        "outputId": "cde8e583-e043-49f5-aa77-3d8fb8420417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eXmeb1Q5OrrH",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Location(الرياض, محافظة الرياض, منطقة الرياض, 11131, السعودية, (24.638916, 46.7160104, 0.0))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latitude = location.latitude\n",
        "longitude = location.longitude\n",
        "\n",
        "print(f'Latitude: {latitude}, longitude: {longitude}')"
      ],
      "metadata": {
        "id": "zVOKCushOs6G",
        "outputId": "72e68064-1759-4328-b7b5-4a910b609c9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zVOKCushOs6G",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latitude: 24.638916, longitude: 46.7160104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "def get_weather_by_city(city_name: str):\n",
        "    # Initialize geocoder\n",
        "    geolocator = Nominatim(user_agent=\"LLMexercise\")\n",
        "\n",
        "    # Get location data (latitude and longitude) for the city\n",
        "    location = geolocator.geocode(city_name)\n",
        "\n",
        "    if location:\n",
        "        latitude = location.latitude\n",
        "        longitude = location.longitude\n",
        "    else:\n",
        "        return f\"City '{city_name}' not found.\"\n",
        "\n",
        "    # Open-Meteo API endpoint with the obtained latitude and longitude\n",
        "    url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
        "\n",
        "    # Send a GET request to the Open-Meteo API\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON data from the response\n",
        "        weather_data = response.json()\n",
        "\n",
        "        # Extract relevant information from the response\n",
        "        current_weather = weather_data.get('current_weather', {})\n",
        "        temperature = current_weather.get('temperature')\n",
        "        windspeed = current_weather.get('windspeed')\n",
        "        winddirection = current_weather.get('winddirection')\n",
        "        weather_time = current_weather.get('time')\n",
        "\n",
        "        # Return the weather information as a formatted string\n",
        "        return (\n",
        "            f\"Current weather in {city_name}:\\n\"\n",
        "            f\"Temperature: {temperature}°C\\n\"\n",
        "            f\"Wind Speed: {windspeed} m/s\\n\"\n",
        "            f\"Wind Direction: {winddirection}°\\n\"\n",
        "            f\"Time of data: {weather_time}\"\n",
        "        )\n",
        "    else:\n",
        "        return \"Failed to retrieve weather data.\"\n",
        "\n",
        "city_name = \"Riyadh Saudi Arabia\"\n",
        "weather_info = get_weather_by_city(city_name)\n",
        "print(weather_info)"
      ],
      "metadata": {
        "id": "Dd_4bTHOOuZy",
        "outputId": "9a6d58c0-8b81-4e71-a27d-1edaacfab6bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Dd_4bTHOOuZy",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current weather in Riyadh Saudi Arabia:\n",
            "Temperature: 39.6°C\n",
            "Wind Speed: 12.8 m/s\n",
            "Wind Direction: 169°\n",
            "Time of data: 2024-09-17T09:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import Tool\n",
        "\n",
        "weather = Tool(\n",
        "    name=\"weather\",\n",
        "    func=get_weather_by_city,\n",
        "    description=\"Gets the weather of a city.\"\n",
        ")"
      ],
      "metadata": {
        "id": "_XWerhvlOwCx"
      },
      "id": "_XWerhvlOwCx",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "# List of tools the agent can use\n",
        "tools = [weather]\n",
        "\n",
        "# Initialize the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")"
      ],
      "metadata": {
        "id": "o-llP7h2Oxx_"
      },
      "id": "o-llP7h2Oxx_",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent.run(\"What is the weather in Riyadh Saudi Arabia?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "EwApxZOxOz22",
        "outputId": "660d9722-d3e7-4f60-f836-a7ed2a74562b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EwApxZOxOz22",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent stopped due to iteration limit or time limit.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}